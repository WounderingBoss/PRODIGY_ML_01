{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction #\n","metadata":{}},{"cell_type":"markdown","source":"Welcome to the feature engineering project for the House Prices - Advanced Regression Techniques competition! This competition uses nearly the same data you used in the exercises of the Feature Engineering course. We'll collect together the work you did into a complete project which you can build off of with ideas of your own.","metadata":{}},{"cell_type":"markdown","source":"# Step 1 - Preliminaries #\n","metadata":{}},{"cell_type":"markdown","source":"## Imports and Configuration\nWe'll start by importing the packages we used in the exercises and setting some notebook defaults. Unhide this cell if you'd like to see the libraries we'll use:","metadata":{}},{"cell_type":"code","source":"import os  # Importing the os module for operating system interactions\nimport warnings  # Importing the warnings module to handle warnings\nfrom pathlib import Path  # Importing the Path class from the pathlib module for filesystem paths\n\nimport matplotlib.pyplot as plt  # Importing matplotlib for plotting\nimport numpy as np  # Importing numpy for numerical computations\nimport pandas as pd  # Importing pandas for data manipulation and analysis\nimport seaborn as sns  # Importing seaborn for statistical data visualization\nfrom IPython.display import display  # Importing display from IPython.display for rich output\nfrom pandas.api.types import CategoricalDtype  # Importing CategoricalDtype for categorical data types\nfrom category_encoders import MEstimateEncoder  # Importing MEstimateEncoder for target encoding\nfrom sklearn.cluster import KMeans  # Importing KMeans for clustering\nfrom sklearn.decomposition import PCA  # Importing PCA for principal component analysis\nfrom sklearn.feature_selection import mutual_info_regression  # Importing mutual_info_regression for feature selection\nfrom sklearn.model_selection import KFold, cross_val_score  # Importing KFold and cross_val_score for cross-validation\nfrom xgboost import XGBRegressor  # Importing XGBRegressor for gradient boosting regression\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")  # Setting default plot style\nplt.rc(\"figure\", autolayout=True)  # Setting default parameters for figures\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)  # Setting default parameters for axes labels and titles\n\n# Mute warnings\nwarnings.filterwarnings('ignore')  # Ignoring all warnings during program execution\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:19:20.660805Z","iopub.execute_input":"2024-02-13T05:19:20.661135Z","iopub.status.idle":"2024-02-13T05:19:20.690386Z","shell.execute_reply.started":"2024-02-13T05:19:20.661112Z","shell.execute_reply":"2024-02-13T05:19:20.689286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\n","metadata":{}},{"cell_type":"markdown","source":"Before we can do any feature engineering, we need to preprocess the data to get it in a form suitable for analysis. The data we used in the course was a bit simpler than the competition data. For the Ames competition dataset, we'll need to:\n\n* Load the data from CSV files\n* Clean the data to fix any errors or inconsistencies\n* Encode the statistical data type (numeric, categorical)\n* Impute any missing values\nWe'll wrap all these steps up in a function, which will make easy for you to get a fresh dataframe whenever you need. After reading the CSV file, we'll apply three preprocessing steps, clean, encode, and impute, and then create the data splits: one (df_train) for training the model, and one (df_test) for making the predictions that you'll submit to the competition for scoring on the leaderboard.","metadata":{}},{"cell_type":"code","source":"def load_data():\n    # Define the directory where the data files are located\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    \n    # Read the training data from the CSV file into a DataFrame, setting the 'Id' column as the index\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    \n    # Read the test data from the CSV file into a DataFrame, setting the 'Id' column as the index\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    \n    # Concatenate the training and test data into a single DataFrame to process them together\n    df = pd.concat([df_train, df_test])\n    \n    # Preprocess the data: clean, encode categorical variables, and impute missing values\n    df = clean(df)\n    df = encode(df)\n    df = impute(df)\n    \n    # Split the combined DataFrame back into training and test sets\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    \n    # Return the preprocessed training and test DataFrames\n    return df_train, df_test\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:07:55.777430Z","iopub.execute_input":"2024-02-13T05:07:55.777764Z","iopub.status.idle":"2024-02-13T05:07:55.784564Z","shell.execute_reply.started":"2024-02-13T05:07:55.777740Z","shell.execute_reply":"2024-02-13T05:07:55.783415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean Data\nSome of the categorical features in this dataset have what are apparently typos in their categories:","metadata":{}},{"cell_type":"code","source":"# Define the directory where the data files are located\ndata_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n\n# Read the CSV file named \"train.csv\" located in the specified directory\n# and set the 'Id' column as the index of the DataFrame\ndf = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n\n# Retrieve the unique values of the column \"Exterior2nd\" in the DataFrame df\nunique_values = df.Exterior2nd.unique()\n\n# Print the unique values of the column \"Exterior2nd\"\nprint(unique_values)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:09:23.365743Z","iopub.execute_input":"2024-02-13T05:09:23.366076Z","iopub.status.idle":"2024-02-13T05:09:23.387999Z","shell.execute_reply.started":"2024-02-13T05:09:23.366051Z","shell.execute_reply":"2024-02-13T05:09:23.387280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing these to `data_description.txt` shows us what needs cleaning. We'll take care of a couple of issues here, but you might want to evaluate this data further.\n\n","metadata":{}},{"cell_type":"code","source":"def clean(df):\n    # Replace the value \"Brk Cmn\" with \"BrkComm\" in the \"Exterior2nd\" column\n    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    \n    # Replace corrupt values of \"GarageYrBlt\" with the year the house was built\n    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n    \n    # Rename columns for easier working with names beginning with numbers\n    df.rename(columns={\n        \"1stFlrSF\": \"FirstFlrSF\",\n        \"2ndFlrSF\": \"SecondFlrSF\",\n        \"3SsnPorch\": \"Threeseasonporch\",\n    }, inplace=True)\n    \n    # Return the cleaned DataFrame\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:10:55.239748Z","iopub.execute_input":"2024-02-13T05:10:55.240092Z","iopub.status.idle":"2024-02-13T05:10:55.246537Z","shell.execute_reply.started":"2024-02-13T05:10:55.240065Z","shell.execute_reply":"2024-02-13T05:10:55.245555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode the Statistical Data Type\nPandas has Python types corresponding to the standard statistical types (numeric, categorical, etc.). Encoding each feature with its correct type helps ensure each feature is treated appropriately by whatever functions we use, and makes it easier for us to apply transformations consistently. This hidden cell defines the encode function:","metadata":{}},{"cell_type":"code","source":"# List of nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n\n# Dictionary defining ordered levels for ordinal categorical features\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add a None level for missing values in the ordered levels\nordered_levels = {key: [\"None\"] + value for key, value in ordered_levels.items()}\n\n# Function to encode categorical features\ndef encode(df):\n    # Encode nominative categorical features\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")  # Convert feature to categorical type\n        # Add a \"None\" category for missing values if it doesn't exist\n        if \"None\" not in df[name].cat.categories:\n            df[name] = df[name].cat.add_categories(\"None\")\n    # Encode ordinal categorical features\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels, ordered=True))  # Convert feature to categorical type with specified levels and order\n    return df  # Return the DataFrame with encoded categorical features\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:12:46.483788Z","iopub.execute_input":"2024-02-13T05:12:46.484153Z","iopub.status.idle":"2024-02-13T05:12:46.493831Z","shell.execute_reply.started":"2024-02-13T05:12:46.484125Z","shell.execute_reply":"2024-02-13T05:12:46.492898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handle Missing Values\nHandling missing values now will make the feature engineering go more smoothly. We'll impute 0 for missing numeric values and \"None\" for missing categorical values. You might like to experiment with other imputation strategies. In particular, you could try creating \"missing value\" indicators: 1 whenever a value was imputed and 0 otherwise.","metadata":{}},{"cell_type":"code","source":"def impute(df):\n    # Iterate over numeric columns and fill missing values with 0\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    \n    # Iterate over categorical columns and fill missing values with \"None\"\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    \n    # Return the DataFrame with imputed missing values\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:22:40.874013Z","iopub.execute_input":"2024-02-13T05:22:40.874452Z","iopub.status.idle":"2024-02-13T05:22:40.881063Z","shell.execute_reply.started":"2024-02-13T05:22:40.874419Z","shell.execute_reply":"2024-02-13T05:22:40.879890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Data\nAnd now we can call the data loader and get the processed data splits:","metadata":{}},{"cell_type":"code","source":"# Call the load_data() function to load and preprocess the data\ndf_train, df_test = load_data()\n\n# Now df_train contains the preprocessed training dataset,\n# and df_test contains the preprocessed test dataset.","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:23:24.007457Z","iopub.execute_input":"2024-02-13T05:23:24.007806Z","iopub.status.idle":"2024-02-13T05:23:24.106042Z","shell.execute_reply.started":"2024-02-13T05:23:24.007780Z","shell.execute_reply":"2024-02-13T05:23:24.105219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You'd like to see what they contain. Notice that df_test is missing values for SalePrice. (NAs were willed with 0's in the imputation step.)","metadata":{}},{"cell_type":"code","source":"# Peek at the values\ndisplay(df_train)\ndisplay(df_test)\n\n# Display information about dtypes and missing values\ndisplay(df_train.info())\ndisplay(df_test.info())","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:24:05.040137Z","iopub.execute_input":"2024-02-13T05:24:05.040475Z","iopub.status.idle":"2024-02-13T05:24:05.148518Z","shell.execute_reply.started":"2024-02-13T05:24:05.040450Z","shell.execute_reply":"2024-02-13T05:24:05.147262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Establish Baseline\nFinally, let's establish a baseline score to judge our feature engineering against.\n\nHere is the function we created in Lesson 1 that will compute the cross-validated RMSLE score for a feature set. We've used XGBoost for our model, but you might want to experiment with other models.","metadata":{}},{"cell_type":"code","source":"def score_dataset(X, y, model=XGBRegressor()):\n    # Label encoding for categoricals\n    #\n    # Label encoding is good for XGBoost and RandomForest, but one-hot\n    # would be better for models like Lasso or Ridge. The `cat.codes`\n    # attribute holds the category levels.\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    \n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    # Convert the target variable y to its natural logarithm\n    log_y = np.log(y)\n    \n    # Perform cross-validation using the negative mean squared error as the scoring metric\n    score = cross_val_score(\n        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n    )\n    \n    # Compute the mean of the negative mean squared error scores\n    score = -1 * score.mean()\n    \n    # Take the square root to obtain the Root Mean Squared Log Error (RMSLE)\n    score = np.sqrt(score)\n    \n    # Return the computed RMSLE score\n    return score\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:26:05.144809Z","iopub.execute_input":"2024-02-13T05:26:05.145168Z","iopub.status.idle":"2024-02-13T05:26:05.151929Z","shell.execute_reply.started":"2024-02-13T05:26:05.145144Z","shell.execute_reply":"2024-02-13T05:26:05.150405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can reuse this scoring function anytime we want to try out a new feature set. We'll run it now on the processed data with no additional features and get a baseline score:","metadata":{}},{"cell_type":"code","source":"# Create a copy of the training DataFrame and assign it to X\nX = df_train.copy()\n\n# Extract the target variable \"SalePrice\" from X and assign it to y\ny = X.pop(\"SalePrice\")\n\n# Evaluate the baseline model by calling the score_dataset() function\nbaseline_score = score_dataset(X, y)\n\n# Print the baseline score\nprint(f\"Baseline score: {baseline_score:.5f} RMSLE\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:27:19.308076Z","iopub.execute_input":"2024-02-13T05:27:19.308416Z","iopub.status.idle":"2024-02-13T05:27:20.905203Z","shell.execute_reply.started":"2024-02-13T05:27:19.308389Z","shell.execute_reply":"2024-02-13T05:27:20.904084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This baseline score helps us to know whether some set of features we've assembled has actually led to any improvement or not.","metadata":{}},{"cell_type":"markdown","source":"# Step 2 - Feature Utility Scores #\nIn Lesson 2 we saw how to use mutual information to compute a utility score for a feature, giving you an indication of how much potential the feature has. This hidden cell defines the two utility functions we used, make_mi_scores and plot_mi_scores:","metadata":{}},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    X = X.copy()\n    # Factorize object and category columns to convert them to integer dtype\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # Determine which features are discrete (integer dtype)\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    # Calculate MI scores using mutual_info_regression\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    # Convert the MI scores to a pandas Series\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    # Sort the MI scores in descending order\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:28:34.357216Z","iopub.execute_input":"2024-02-13T05:28:34.357560Z","iopub.status.idle":"2024-02-13T05:28:34.364085Z","shell.execute_reply.started":"2024-02-13T05:28:34.357536Z","shell.execute_reply":"2024-02-13T05:28:34.363045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`plot_mi_scores` plots the MI scores calculated by the make_mi_scores function. It visualizes the importance of each feature based on its MI score.","metadata":{}},{"cell_type":"code","source":"def plot_mi_scores(scores):\n    # Sort the scores in ascending order\n    scores = scores.sort_values(ascending=True)\n    # Create an array for horizontal bar plotting\n    width = np.arange(len(scores))\n    # Get the feature names as ticks for the y-axis\n    ticks = list(scores.index)\n    # Create a horizontal bar plot\n    plt.barh(width, scores)\n    # Set the y-ticks and labels\n    plt.yticks(width, ticks)\n    # Set the title of the plot\n    plt.title(\"Mutual Information Scores\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:30:06.336719Z","iopub.execute_input":"2024-02-13T05:30:06.337070Z","iopub.status.idle":"2024-02-13T05:30:06.343139Z","shell.execute_reply.started":"2024-02-13T05:30:06.337045Z","shell.execute_reply":"2024-02-13T05:30:06.342198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at our feature scores again:\n\n","metadata":{}},{"cell_type":"code","source":"# Create a copy of the training DataFrame and assign it to X\nX = df_train.copy()\n\n# Extract the target variable \"SalePrice\" from X and assign it to y\ny = X.pop(\"SalePrice\")\n\n# Calculate the Mutual Information scores using the make_mi_scores function\nmi_scores = make_mi_scores(X, y)\n\n# Print the MI scores\nmi_scores\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:31:05.095490Z","iopub.execute_input":"2024-02-13T05:31:05.095787Z","iopub.status.idle":"2024-02-13T05:31:06.780352Z","shell.execute_reply.started":"2024-02-13T05:31:05.095765Z","shell.execute_reply":"2024-02-13T05:31:06.779344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see that we have a number of features that are highly informative and also some that don't seem to be informative at all (at least by themselves). As we talked about in Tutorial 2, the top scoring features will usually pay-off the most during feature development, so it could be a good idea to focus your efforts on those. On the other hand, training on uninformative features can lead to overfitting. So, the features with 0.0 scores we'll drop entirely:","metadata":{}},{"cell_type":"code","source":"def drop_uninformative(df, mi_scores):\n    # Select only the columns with MI scores greater than 0.0\n    return df.loc[:, mi_scores > 0.0]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:31:46.029809Z","iopub.execute_input":"2024-02-13T05:31:46.030149Z","iopub.status.idle":"2024-02-13T05:31:46.034550Z","shell.execute_reply.started":"2024-02-13T05:31:46.030125Z","shell.execute_reply":"2024-02-13T05:31:46.033496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing them does lead to a modest performance gain:\n\n","metadata":{}},{"cell_type":"code","source":"X = df_train.copy()  # Create a copy of the training DataFrame\ny = X.pop(\"SalePrice\")  # Extract the target variable \"SalePrice\" from X\n\n# Drop uninformative features from X based on MI scores\nX = drop_uninformative(X, mi_scores)\n\n# Evaluate the performance of the dataset X using the score_dataset() function\nscore_dataset(X, y)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:32:09.645185Z","iopub.execute_input":"2024-02-13T05:32:09.645510Z","iopub.status.idle":"2024-02-13T05:32:11.033662Z","shell.execute_reply.started":"2024-02-13T05:32:09.645486Z","shell.execute_reply":"2024-02-13T05:32:11.032815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Later, we'll add the `drop_uninformative function` to our feature-creation pipeline.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Step 3 - Create Features #\nNow we'll start developing our feature set.\n\nTo make our feature engineering workflow more modular, we'll define a function that will take a prepared dataframe and pass it through a pipeline of transformations to get the final feature set. It will look something like this:","metadata":{}},{"cell_type":"code","source":"def create_features(df):\n    # Create a copy of the DataFrame and assign it to X\n    X = df.copy()\n    # Extract the target variable \"SalePrice\" from X and assign it to y\n    y = X.pop(\"SalePrice\")\n    # Join the features created by create_features_1 with X\n    X = X.join(create_features_1(X))\n    # Join the features created by create_features_2 with X\n    X = X.join(create_features_2(X))\n    # Join the features created by create_features_3 with X\n    X = X.join(create_features_3(X))\n    # ...\n    # Return the DataFrame with the additional features\n    return X\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:33:15.883271Z","iopub.execute_input":"2024-02-13T05:33:15.883626Z","iopub.status.idle":"2024-02-13T05:33:15.889836Z","shell.execute_reply.started":"2024-02-13T05:33:15.883602Z","shell.execute_reply":"2024-02-13T05:33:15.888679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's go ahead and define one transformation now, a [label encoding](https://www.kaggle.com/code/alexisbcook/categorical-variables/tutorial) for the categorical features:\n\n","metadata":{}},{"cell_type":"code","source":"def label_encode(df):\n    # Create a copy of the DataFrame and assign it to X\n    X = df.copy()\n    # Iterate over columns with data type \"category\"\n    for colname in X.select_dtypes([\"category\"]):\n        # Label encode the values in each categorical column\n        X[colname] = X[colname].cat.codes\n    # Return the DataFrame with label encoded categorical features\n    return X\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:34:22.735780Z","iopub.execute_input":"2024-02-13T05:34:22.736103Z","iopub.status.idle":"2024-02-13T05:34:22.741723Z","shell.execute_reply.started":"2024-02-13T05:34:22.736082Z","shell.execute_reply":"2024-02-13T05:34:22.740510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A label encoding is okay for any kind of categorical feature when you're using a tree-ensemble like XGBoost, even for unordered categories. If you wanted to try a linear regression model (also popular in this competition), you would instead want to use a one-hot encoding, especially for the features with unordered categories.","metadata":{}},{"cell_type":"markdown","source":"### Create Features with Pandas\nThis cell reproduces the work you did in Exercise 3, where you applied strategies for creating features in Pandas. Modify or add to these functions to try out other feature combinations.\n\n","metadata":{}},{"cell_type":"code","source":"def mathematical_transforms(df):\n    # Create a new DataFrame to hold the new features\n    X = pd.DataFrame()\n    # Calculate the ratio of living area to lot area and assign it to \"LivLotRatio\"\n    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n    # Calculate the ratio of total floor area to total rooms above ground and assign it to \"Spaciousness\"\n    X[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n    return X\n\ndef interactions(df):\n    # Create dummy variables for building type and multiply them by living area to create interaction features\n    X = pd.get_dummies(df.BldgType, prefix=\"Bldg\").mul(df.GrLivArea, axis=0)\n    return X\n\ndef counts(df):\n    # Count the number of different types of porches for each row and assign it to \"PorchTypes\"\n    X = pd.DataFrame()\n    X[\"PorchTypes\"] = df[[\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"Threeseasonporch\", \"ScreenPorch\"]].gt(0.0).sum(axis=1)\n    return X\n\ndef break_down(df):\n    # Extract the main class from the MSSubClass column and assign it to \"MSClass\"\n    X = pd.DataFrame()\n    X[\"MSClass\"] = df.MSSubClass.str.split(\"_\", n=1, expand=True)[0]\n    return X\n\ndef group_transforms(df):\n    # Calculate the median living area for each neighborhood and assign it to each row within the same neighborhood\n    X = pd.DataFrame()\n    X[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n    return X\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:35:59.682724Z","iopub.execute_input":"2024-02-13T05:35:59.683078Z","iopub.status.idle":"2024-02-13T05:35:59.691225Z","shell.execute_reply.started":"2024-02-13T05:35:59.683047Z","shell.execute_reply":"2024-02-13T05:35:59.690108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are some ideas for other transforms you could explore:\n\n* Interactions between the quality Qual and condition Cond features. OverallQual, for instance, was a high-scoring feature. You could try combining it with OverallCond by converting both to integer type and taking a product.\n* Square roots of area features. This would convert units of square feet to just feet.\n* Logarithms of numeric features. If a feature has a skewed distribution, applying a logarithm can help normalize it.\n* Interactions between numeric and categorical features that describe the same thing. You could look at interactions between BsmtQual and TotalBsmtSF, for instance.\n* Other group statistics in Neighboorhood. We did the median of GrLivArea. Looking at mean, std, or count could be interesting. You could also try combining the group statistics with other features. Maybe the difference of GrLivArea and the median is important?","metadata":{}},{"cell_type":"markdown","source":"k-Means Clustering\nThe first unsupervised algorithm we used to create features was k-means clustering. We saw that you could either use the cluster labels as a feature (a column with `0, 1, 2, ...`) or you could use the distance of the observations to each cluster. We saw how these features can sometimes be effective at untangling complicated spatial relationships.","metadata":{}},{"cell_type":"code","source":"cluster_features = [\n    \"LotArea\",\n    \"TotalBsmtSF\",\n    \"FirstFlrSF\",\n    \"SecondFlrSF\",\n    \"GrLivArea\",\n]\n\ndef cluster_labels(df, features, n_clusters=20):\n    # Create a copy of the DataFrame and select only the specified features for clustering\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    # Scale the selected features to have zero mean and unit variance\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    # Apply K-means clustering with the specified number of clusters\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    # Assign cluster labels to each data point and store them in a new DataFrame\n    X_new = pd.DataFrame()\n    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n    return X_new\n\ndef cluster_distance(df, features, n_clusters=20):\n    # Create a copy of the DataFrame and select only the specified features for clustering\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    # Scale the selected features to have zero mean and unit variance\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    # Apply K-means clustering with the specified number of clusters\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    # Compute the Euclidean distance of each data point to the centroids of the clusters\n    X_cd = kmeans.fit_transform(X_scaled)\n    # Label the distance features and join them to the original dataset\n    X_cd = pd.DataFrame(X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])])\n    return X_cd\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:38:04.273912Z","iopub.execute_input":"2024-02-13T05:38:04.274281Z","iopub.status.idle":"2024-02-13T05:38:04.282173Z","shell.execute_reply.started":"2024-02-13T05:38:04.274255Z","shell.execute_reply":"2024-02-13T05:38:04.281245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Principal Component AnalysisÂ¶\nPCA was the second unsupervised model we used for feature creation. We saw how it could be used to decompose the variational structure in the data. The PCA algorithm gave us loadings which described each component of variation, and also the components which were the transformed datapoints. The loadings can suggest features to create and the components we can use as features directly.\n\nHere are the utility functions from the PCA lesson:","metadata":{}},{"cell_type":"code","source":"def apply_pca(X, standardize=True):\n    # Standardize the data if specified\n    if standardize:\n        X = (X - X.mean(axis=0)) / X.std(axis=0)\n    \n    # Create a PCA object\n    pca = PCA()\n    \n    # Fit PCA to the standardized data and transform it\n    X_pca = pca.fit_transform(X)\n    \n    # Convert the transformed data to a DataFrame with appropriate column names\n    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n    X_pca = pd.DataFrame(X_pca, columns=component_names)\n    \n    # Create loadings DataFrame\n    loadings = pd.DataFrame(\n        pca.components_.T,  # Transpose the matrix of loadings\n        columns=component_names,  # Principal components as columns\n        index=X.columns,  # Original features as rows\n    )\n    \n    # Return PCA object, transformed data, and loadings\n    return pca, X_pca, loadings\n\n\ndef plot_variance(pca, width=8, dpi=100):\n    # Create a figure with two subplots\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    \n    # Plot explained variance ratio\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0))\n    \n    # Plot cumulative variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0))\n    \n    # Set figure properties\n    fig.set(figwidth=width, dpi=dpi)\n    \n    # Return the axes\n    return axs\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:39:17.438743Z","iopub.execute_input":"2024-02-13T05:39:17.439142Z","iopub.status.idle":"2024-02-13T05:39:17.448831Z","shell.execute_reply.started":"2024-02-13T05:39:17.439116Z","shell.execute_reply":"2024-02-13T05:39:17.447541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here are transforms that produce the features from the Exercise 5. You might want to change these if you came up with a different answer.","metadata":{}},{"cell_type":"code","source":"def pca_inspired(df):\n    # Create a new DataFrame to hold the PCA-inspired features\n    X = pd.DataFrame()\n    \n    # Create Feature1 by adding GrLivArea and TotalBsmtSF\n    X[\"Feature1\"] = df.GrLivArea + df.TotalBsmtSF\n    \n    # Create Feature2 by multiplying YearRemodAdd and TotalBsmtSF\n    X[\"Feature2\"] = df.YearRemodAdd * df.TotalBsmtSF\n    \n    return X\n\ndef pca_components(df, features):\n    # Select the specified features from the DataFrame\n    X = df.loc[:, features]\n    \n    # Apply PCA to the selected features using the apply_pca function\n    _, X_pca, _ = apply_pca(X)\n    \n    return X_pca\n\n# List of features used for PCA\npca_features = [\n    \"GarageArea\",\n    \"YearRemodAdd\",\n    \"TotalBsmtSF\",\n    \"GrLivArea\",\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:40:14.304522Z","iopub.execute_input":"2024-02-13T05:40:14.304884Z","iopub.status.idle":"2024-02-13T05:40:14.311293Z","shell.execute_reply.started":"2024-02-13T05:40:14.304859Z","shell.execute_reply":"2024-02-13T05:40:14.310280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are only a couple ways you could use the principal components. You could also try clustering using one or more components. One thing to note is that PCA doesn't change the distance between points -- it's just like a rotation. So clustering with the full set of components is the same as clustering with the original features. Instead, pick some subset of components, maybe those with the most variance or the highest MI scores.\n\nFor further analysis, you might want to look at a correlation matrix for the dataset:","metadata":{}},{"cell_type":"code","source":"def corrplot(df, method=\"pearson\", annot=True, **kwargs):\n    \"\"\"\n    Plot a correlation matrix heatmap.\n\n    Parameters:\n        df (DataFrame): The DataFrame containing the data.\n        method (str): The correlation method to use ('pearson', 'kendall', 'spearman').\n        annot (bool): Whether to annotate the heatmap with correlation values.\n        **kwargs: Additional keyword arguments to pass to sns.clustermap.\n\n    Returns:\n        None\n    \"\"\"\n    # Calculate the correlation matrix using the specified method\n    corr_matrix = df.corr(method=method, numeric_only=True)\n    \n    # Create a clustermap of the correlation matrix\n    sns.clustermap(\n        corr_matrix,\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n        method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\n\n# Plot the correlation matrix heatmap for df_train with annotations disabled\ncorrplot(df_train, annot=None)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:40:53.250844Z","iopub.execute_input":"2024-02-13T05:40:53.251199Z","iopub.status.idle":"2024-02-13T05:40:54.304326Z","shell.execute_reply.started":"2024-02-13T05:40:53.251173Z","shell.execute_reply":"2024-02-13T05:40:54.303421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Groups of highly correlated features often yield interesting loadings.\n\n### PCA Application - Indicate Outliers\nIn Exercise 5, you applied PCA to determine houses that were **outliers**, that is, houses having values not well represented in the rest of the data. You saw that there was a group of houses in the `Edwards` neighborhood having a `SaleCondition` of `Partial` whose values were especially extreme.\n\nSome models can benefit from having these outliers indicated, which is what this next transform will do.","metadata":{}},{"cell_type":"code","source":"def indicate_outliers(df):\n    \"\"\"\n    Create a binary indicator for outliers based on specific conditions.\n\n    Parameters:\n        df (DataFrame): The DataFrame containing the data.\n\n    Returns:\n        DataFrame: A DataFrame containing a binary indicator for outliers.\n    \"\"\"\n    # Create a new DataFrame to hold the outlier indicator\n    X_new = pd.DataFrame()\n    \n    # Define conditions for outliers based on specific columns\n    # For example, outliers are defined as properties in the \"Edwards\" neighborhood with a \"Partial\" sale condition\n    X_new[\"Outlier\"] = (df.Neighborhood == \"Edwards\") & (df.SaleCondition == \"Partial\")\n    \n    return X_new\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:42:25.682741Z","iopub.execute_input":"2024-02-13T05:42:25.683468Z","iopub.status.idle":"2024-02-13T05:42:25.688665Z","shell.execute_reply.started":"2024-02-13T05:42:25.683437Z","shell.execute_reply":"2024-02-13T05:42:25.687824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You could also consider applying some sort of robust scaler from scikit-learn's `sklearn.preprocessing` module to the outlying values, especially those in `GrLivArea.` [Here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html) is a tutorial illustrating some of them. Another option could be to create a feature of \"outlier scores\" using one of scikit-learn's [outlier detectors](https://scikit-learn.org/stable/modules/outlier_detection.html).","metadata":{}},{"cell_type":"markdown","source":"Target Encoding\nNeeding a separate holdout set to create a target encoding is rather wasteful of data. In Tutorial 6 we used 25% of our dataset just to encode a single feature, `Zipcode`. The data from the other features in that 25% we didn't get to use at all.\n\nThere is, however, a way you can use target encoding without having to use held-out encoding data. It's basically the same trick used in cross-validation:\n\n1. Split the data into folds, each fold having two splits of the dataset.\n1. Train the encoder on one split but transform the values of the other.\n1. Repeat for all the splits.\nThis way, training and transformation always take place on independent sets of data, just like when you use a holdout set but without any data going to waste.\n\nIn the next hidden cell is a wrapper you can use with any target encoder:","metadata":{}},{"cell_type":"code","source":"class CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        \"\"\"\n        Initialize the CrossFoldEncoder.\n\n        Parameters:\n            encoder: The encoder object to be used.\n            **kwargs: Additional keyword arguments for the encoder.\n\n        Returns:\n            None\n        \"\"\"\n        self.encoder_ = encoder  # The encoder object\n        self.kwargs_ = kwargs  # Additional keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=5)  # Initialize a 5-fold cross-validator\n\n    def fit_transform(self, X, y, cols):\n        \"\"\"\n        Fit and transform the data using the CrossFoldEncoder.\n\n        Parameters:\n            X: The input features DataFrame.\n            y: The target variable Series.\n            cols: The columns to encode.\n\n        Returns:\n            DataFrame: The transformed features DataFrame.\n        \"\"\"\n        self.fitted_encoders_ = []  # List to hold fitted encoders for each fold\n        self.cols_ = cols  # Columns to encode\n        X_encoded = []  # List to hold encoded data from each fold\n        # Iterate over each fold\n        for idx_encode, idx_train in self.cv_.split(X):\n            # Instantiate a new encoder for the fold\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            # Fit the encoder on the training data of the fold\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            # Transform the training data of the fold\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            # Store the fitted encoder for later use\n            self.fitted_encoders_.append(fitted_encoder)\n        # Concatenate the encoded data from all folds\n        X_encoded = pd.concat(X_encoded)\n        # Rename the columns of the concatenated DataFrame\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    def transform(self, X):\n        \"\"\"\n        Transform the test data using the fitted encoders.\n\n        Parameters:\n            X: The input features DataFrame.\n\n        Returns:\n            DataFrame: The transformed features DataFrame.\n        \"\"\"\n        from functools import reduce\n\n        X_encoded_list = []  # List to hold encoded data from each fold\n        # Iterate over each fitted encoder\n        for fitted_encoder in self.fitted_encoders_:\n            # Transform the test data using the fitted encoder\n            X_encoded = fitted_encoder.transform(X)\n            # Extract only the columns used for encoding\n            X_encoded_list.append(X_encoded[self.cols_])\n        # Calculate the average of the encoded data from all folds\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        # Rename the columns of the resulting DataFrame\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:45:09.449559Z","iopub.execute_input":"2024-02-13T05:45:09.449882Z","iopub.status.idle":"2024-02-13T05:45:09.459943Z","shell.execute_reply.started":"2024-02-13T05:45:09.449859Z","shell.execute_reply":"2024-02-13T05:45:09.459084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use it like:\n\n","metadata":{}},{"cell_type":"code","source":"# Instantiate a CrossFoldEncoder with MEstimateEncoder as the encoder and m=1 as a parameter\nencoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n\n# Fit and transform the data using the CrossFoldEncoder\n# Assume X is your feature DataFrame and y is your target variable Series\n# Specify the columns to encode as [\"MSSubClass\"]\nX_encoded = encoder.fit_transform(X, y, cols=[\"MSSubClass\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:45:43.481045Z","iopub.execute_input":"2024-02-13T05:45:43.481365Z","iopub.status.idle":"2024-02-13T05:45:43.575266Z","shell.execute_reply.started":"2024-02-13T05:45:43.481341Z","shell.execute_reply":"2024-02-13T05:45:43.574236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can turn any of the encoders from the `category_encoders` library into a cross-fold encoder. The `CatBoostEncoder` would be worth trying. It's similar to `MEstimateEncoder` but uses some tricks to better prevent overfitting. Its smoothing parameter is called `a` instead of `m.`","metadata":{}},{"cell_type":"markdown","source":"### Create Final Feature Set\nNow let's combine everything together. Putting the transformations into separate functions makes it easier to experiment with various combinations. The ones I left uncommented I found gave the best results. You should experiment with you own ideas though! Modify any of these transformations or come up with some of your own to add to the pipeline.","metadata":{}},{"cell_type":"code","source":"def create_features(df, df_test=None):\n    \"\"\"\n    Generate features for a machine learning model.\n\n    Parameters:\n        df (DataFrame): The training DataFrame.\n        df_test (DataFrame, optional): The test DataFrame. Default is None.\n\n    Returns:\n        DataFrame or tuple of DataFrames: The transformed training DataFrame or tuple of transformed training and test DataFrames.\n    \"\"\"\n    X = df.copy()  # Make a copy of the training DataFrame\n    y = X.pop(\"SalePrice\")  # Remove the target variable from the training DataFrame\n    mi_scores = make_mi_scores(X, y)  # Compute Mutual Information scores\n\n    # Combine training and test splits if test data is provided\n    if df_test is not None:\n        X_test = df_test.copy()\n        X_test.pop(\"SalePrice\")\n        X = pd.concat([X, X_test])\n\n    # Lesson 2 - Mutual Information: Drop uninformative features\n    X = drop_uninformative(X, mi_scores)\n\n    # Lesson 3 - Transformations: Apply mathematical transformations, create interactions, and count features\n    X = X.join(mathematical_transforms(X))\n    X = X.join(interactions(X))\n    X = X.join(counts(X))\n    X = X.join(group_transforms(X))\n\n    # Lesson 5 - PCA: Apply PCA-inspired feature creation\n    X = X.join(pca_inspired(X))\n\n    # Label encoding for categorical features\n    X = label_encode(X)\n\n    # Reform splits if test data is provided\n    if df_test is not None:\n        X_test = X.loc[df_test.index, :]\n        X.drop(df_test.index, inplace=True)\n\n    # Lesson 6 - Target Encoder: Apply target encoding using CrossFoldEncoder\n    encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n    X = X.join(encoder.fit_transform(X, y, cols=[\"MSSubClass\"]))\n    if df_test is not None:\n        X_test = X_test.join(encoder.transform(X_test))\n\n    # Return the transformed training DataFrame or tuple of transformed training and test DataFrames\n    if df_test is not None:\n        return X, X_test\n    else:\n        return X\n\n\n# Load training and test data\ndf_train, df_test = load_data()\n\n# Create features for the training data\nX_train = create_features(df_train)\ny_train = df_train.loc[:, \"SalePrice\"]\n\n# Evaluate the model using the transformed training data\nscore_dataset(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:47:40.220173Z","iopub.execute_input":"2024-02-13T05:47:40.220488Z","iopub.status.idle":"2024-02-13T05:47:43.854418Z","shell.execute_reply.started":"2024-02-13T05:47:40.220449Z","shell.execute_reply":"2024-02-13T05:47:43.853399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4 - Hyperparameter Tuning #\nAt this stage, you might like to do some hyperparameter tuning with XGBoost before creating your final submission.","metadata":{}},{"cell_type":"code","source":"# Create features for the training data\nX_train = create_features(df_train)\ny_train = df_train.loc[:, \"SalePrice\"]\n\n# Define XGBoost parameters\nxgb_params = dict(\n    max_depth=6,           # maximum depth of each tree\n    learning_rate=0.01,    # effect of each tree\n    n_estimators=1000,     # number of trees\n    min_child_weight=1,    # minimum number of houses in a leaf\n    colsample_bytree=0.7,  # fraction of features per tree\n    subsample=0.7,         # fraction of instances per tree\n    reg_alpha=0.5,         # L1 regularization\n    reg_lambda=1.0,        # L2 regularization\n    num_parallel_tree=1,   # set > 1 for boosted random forests\n)\n\n# Instantiate the XGBoost regressor with the specified parameters\nxgb = XGBRegressor(**xgb_params)\n\n# Evaluate the model using the transformed training data\nscore = score_dataset(X_train, y_train, xgb)\nprint(f\"XGBoost model score: {score:.5f} RMSLE\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:48:25.625184Z","iopub.execute_input":"2024-02-13T05:48:25.626527Z","iopub.status.idle":"2024-02-13T05:48:40.187958Z","shell.execute_reply.started":"2024-02-13T05:48:25.626486Z","shell.execute_reply":"2024-02-13T05:48:40.187083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just tuning these by hand can give you great results. However, you might like to try using one of scikit-learn's automatic [hyperparameter tuners](https://scikit-learn.org/stable/modules/grid_search.html). Or you could explore more advanced tuning libraries like [Optuna](https://optuna.readthedocs.io/en/stable/index.html) or [scikit-optimize](https://scikit-optimize.github.io/stable/).\n\nHere is how you can use Optuna with XGBoost:","metadata":{}},{"cell_type":"code","source":"import optuna\n\ndef objective(trial):\n    # Define the search space for hyperparameters\n    xgb_params = dict(\n        max_depth=trial.suggest_int(\"max_depth\", 2, 10),  # maximum depth of each tree\n        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),  # effect of each tree\n        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),  # number of trees\n        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),  # minimum number of houses in a leaf\n        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),  # fraction of features per tree\n        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),  # fraction of instances per tree\n        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),  # L1 regularization\n        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),  # L2 regularization\n    )\n    # Create XGBoost regressor with the suggested hyperparameters\n    xgb = XGBRegressor(**xgb_params)\n    # Evaluate the model using the transformed training data and return the score\n    return score_dataset(X_train, y_train, xgb)\n\n# Create a study object for optimization, minimizing the objective function\nstudy = optuna.create_study(direction=\"minimize\")\n# Optimize the hyperparameters with a specified number of trials\nstudy.optimize(objective, n_trials=20)\n\n# Get the best hyperparameters found during optimization\nxgb_params = study.best_params\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T05:52:07.850879Z","iopub.execute_input":"2024-02-13T05:52:07.851489Z","iopub.status.idle":"2024-02-13T06:01:16.581554Z","shell.execute_reply.started":"2024-02-13T05:52:07.851441Z","shell.execute_reply":"2024-02-13T06:01:16.580843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Copy this into a code cell if you'd like to use it, but be aware that it will take quite a while to run. After it's done, you might enjoy using some of [Optuna's visualizations](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html).","metadata":{}},{"cell_type":"markdown","source":"# Step 5 - Train Model and Create Submissions #\nOnce you're satisfied with everything, it's time to create your final predictions! This cell will:\n\n* create your feature set from the original data\n* train XGBoost on the training data\n* use the trained model to make predictions from the test set\n* save the predictions to a CSV file","metadata":{}},{"cell_type":"code","source":"X_train, X_test = create_features(df_train, df_test)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nxgb = XGBRegressor(**xgb_params)\n# XGB minimizes MSE, but competition loss is RMSLE\n# So, we need to log-transform y to train and exp-transform the predictions\nxgb.fit(X_train, np.log(y_train))\npredictions = np.exp(xgb.predict(X_test))\n\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:03:49.084502Z","iopub.execute_input":"2024-02-13T06:03:49.084842Z","iopub.status.idle":"2024-02-13T06:03:55.705521Z","shell.execute_reply.started":"2024-02-13T06:03:49.084817Z","shell.execute_reply":"2024-02-13T06:03:55.704738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To submit these predictions to the competition, follow these steps:\n\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window. This will generate a pop-up window.\n1. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n1. This generates a window in the bottom left corner of the notebook. After it has finished running, click on the number to the right of the **Save Version** button. This pulls up a list of versions on the right of the screen. Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n1. Click on the **Output** tab on the right of the screen. Then, click on the file you would like to submit, and click on the blue **Submit** button to submit your results to the leaderboard.\nYou have now successfully submitted to the competition!","metadata":{}},{"cell_type":"markdown","source":"# Next Steps #\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\nBe sure to check out [other users' notebooks](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/notebooks) in this competition. You'll find lots of great ideas for new features and as well as other ways to discover more things about the dataset or make better predictions. There's also the [discussion forum](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion), where you can share ideas with other Kagglers.\n\nHave fun Kaggling!","metadata":{}},{"cell_type":"markdown","source":"\nHave questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/feature-engineering/discussion) to chat with other learners.","metadata":{}}]}